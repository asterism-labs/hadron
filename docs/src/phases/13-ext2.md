# Phase 13: ext2 Filesystem

Previously Phase 12. The design is conceptually unchanged but all block I/O uses the async VFS trait introduced in Phase 8, enabling concurrent block reads within a single file operation.

## Goal

Implement a read-only ext2 filesystem driver, later extended with write support. Mount an ext2 partition from a VirtIO block device, resolve paths, and read file contents. All I/O goes through the async `BlockDevice` trait, so block reads are non-blocking and composable with the executor.

## Files to Create/Modify

| File | Description |
|------|-------------|
| `hadron-kernel/src/fs/ext2/mod.rs` | `Ext2Fs` implementing `FileSystem` trait |
| `hadron-kernel/src/fs/ext2/superblock.rs` | Superblock parsing and validation |
| `hadron-kernel/src/fs/ext2/block_group.rs` | Block group descriptor table |
| `hadron-kernel/src/fs/ext2/inode.rs` | Inode reading, block mapping (direct/indirect) |
| `hadron-kernel/src/fs/ext2/dir.rs` | Directory entry iteration and path lookup |
| `hadron-kernel/src/fs/ext2/alloc.rs` | Block/inode allocation bitmaps (write support, later) |

## Key Design

### ext2 On-Disk Layout

An ext2 volume is divided into fixed-size block groups. The superblock at byte offset 1024 describes the filesystem geometry. Block size is `1024 << log_block_size`.

Each block group contains: a block bitmap, an inode bitmap, an inode table, and data blocks. The block group descriptor table (located in the block immediately after the superblock) provides the block numbers for these structures.

### Async VFS Integration

The ext2 driver implements the async `Inode` trait from Phase 8. All block reads go through `AsyncBlockDevice::read_sector()`, which returns a future. This means:

- Reading a file's data blocks can issue multiple concurrent reads via `join()`.
- Resolving indirect block chains awaits each level sequentially (inherent data dependency) but individual block reads within a level can be parallelized.
- The executor schedules other tasks while block I/O is in flight.

```rust
impl Inode for Ext2Inode {
    async fn read(&self, offset: usize, buf: &mut [u8]) -> Result<usize, FsError> {
        let block_size = self.fs.block_size();
        let start_block = offset / block_size;
        let end_block = (offset + buf.len()).div_ceil(block_size);

        for logical in start_block..end_block {
            let physical = self.resolve_block(logical).await?;
            self.fs.device.read_sector(physical, &mut block_buf).await?;
            // Copy relevant bytes into buf
        }
        Ok(bytes_read)
    }
}
```

### resolve_block(): Logical to Physical Block Mapping

Inodes store 15 block pointers: 12 direct (blocks 0-11), one single-indirect (block 12), one double-indirect (block 13), and one triple-indirect (block 14). Each indirect block contains `block_size / 4` 32-bit block pointers.

```rust
/// Map a logical block number to a physical block number.
/// Each indirection level requires an async block read.
pub async fn resolve_block(
    &self,
    logical: u32,
    device: &dyn AsyncBlockDevice,
    block_size: usize,
) -> Result<u32, Ext2Error> {
    let ptrs_per_block = (block_size / 4) as u32;

    if logical < 12 {
        // Direct block
        Ok(self.block[logical as usize])
    } else if logical < 12 + ptrs_per_block {
        // Single indirect: read one indirect block
        let indirect_block = self.block[12];
        let index = logical - 12;
        read_block_ptr(device, indirect_block, index, block_size).await
    } else if logical < 12 + ptrs_per_block + ptrs_per_block.pow(2) {
        // Double indirect: two levels of indirection
        let adjusted = logical - 12 - ptrs_per_block;
        let l1_index = adjusted / ptrs_per_block;
        let l2_index = adjusted % ptrs_per_block;
        let l1_block = read_block_ptr(device, self.block[13], l1_index, block_size).await?;
        read_block_ptr(device, l1_block, l2_index, block_size).await
    } else {
        // Triple indirect: three levels of indirection
        let adjusted = logical - 12 - ptrs_per_block - ptrs_per_block.pow(2);
        let l1_index = adjusted / ptrs_per_block.pow(2);
        let l2_index = (adjusted / ptrs_per_block) % ptrs_per_block;
        let l3_index = adjusted % ptrs_per_block;
        let l1_block = read_block_ptr(device, self.block[14], l1_index, block_size).await?;
        let l2_block = read_block_ptr(device, l1_block, l2_index, block_size).await?;
        read_block_ptr(device, l2_block, l3_index, block_size).await
    }
}
```

## Key Data Structures

### ext2 Superblock

```rust
#[repr(C)]
pub struct Ext2Superblock {
    pub inodes_count: u32,
    pub blocks_count: u32,
    pub r_blocks_count: u32,
    pub free_blocks_count: u32,
    pub free_inodes_count: u32,
    pub first_data_block: u32,
    pub log_block_size: u32,       // Block size = 1024 << log_block_size
    pub log_frag_size: u32,
    pub blocks_per_group: u32,
    pub frags_per_group: u32,
    pub inodes_per_group: u32,
    pub mtime: u32,
    pub wtime: u32,
    pub mnt_count: u16,
    pub max_mnt_count: u16,
    pub magic: u16,                // Must be 0xEF53
    pub state: u16,
    pub errors: u16,
    pub minor_rev_level: u16,
    // ... additional fields omitted
}

impl Ext2Superblock {
    pub fn block_size(&self) -> usize {
        1024 << self.log_block_size
    }

    pub fn validate(&self) -> Result<(), Ext2Error> {
        if self.magic != 0xEF53 {
            return Err(Ext2Error::BadMagic);
        }
        Ok(())
    }
}
```

### Block Group Descriptor

```rust
#[repr(C)]
pub struct BlockGroupDescriptor {
    pub block_bitmap: u32,
    pub inode_bitmap: u32,
    pub inode_table: u32,
    pub free_blocks_count: u16,
    pub free_inodes_count: u16,
    pub used_dirs_count: u16,
    pub pad: u16,
    pub reserved: [u8; 12],
}
```

### ext2 Inode

```rust
#[repr(C)]
pub struct Ext2RawInode {
    pub mode: u16,
    pub uid: u16,
    pub size: u32,
    pub atime: u32,
    pub ctime: u32,
    pub mtime: u32,
    pub dtime: u32,
    pub gid: u16,
    pub links_count: u16,
    pub blocks: u32,         // Count of 512-byte blocks
    pub flags: u32,
    pub osd1: u32,
    pub block: [u32; 15],    // 0-11 direct, 12 indirect, 13 double, 14 triple
    pub generation: u32,
    pub file_acl: u32,
    pub dir_acl: u32,        // Upper 32 bits of size for regular files
    pub faddr: u32,
    pub osd2: [u8; 12],
}
```

### Directory Entry

```rust
#[repr(C)]
pub struct Ext2DirEntry {
    pub inode: u32,
    pub rec_len: u16,        // Total entry length including padding
    pub name_len: u8,
    pub file_type: u8,
    // Followed by name[name_len], NOT null-terminated
}

/// Walk directory data as a linked list of entries.
/// Each entry is rec_len bytes apart.
pub fn iterate_dir(dir_data: &[u8]) -> impl Iterator<Item = (u32, u8, &str)> + '_ {
    // Yields (inode, file_type, name) for each valid entry
}
```

### Ext2Fs

```rust
pub struct Ext2Fs {
    device: Arc<dyn AsyncBlockDevice>,
    superblock: Ext2Superblock,
    block_groups: Vec<BlockGroupDescriptor>,
    block_size: usize,
}

impl FileSystem for Ext2Fs {
    fn name(&self) -> &str { "ext2" }

    fn root(&self) -> Arc<dyn Inode> {
        // Inode 2 is always the root directory in ext2
        self.read_inode(2).unwrap()
    }
}
```

## Frame vs Service

| Component | Layer | Reason |
|-----------|-------|--------|
| All ext2 code | Service | Interacts with hardware only through `AsyncBlockDevice` trait |
| Superblock parsing | Service | Byte-level parsing of block reads |
| Inode resolution | Service | Computation + async block reads |
| Directory iteration | Service | Byte parsing over directory data |
| Block/inode allocation | Service | Bitmap manipulation + block writes |

The entire ext2 implementation is safe service code. No direct hardware access, no unsafe operations beyond what the block device trait encapsulates.

## Milestone

**Verification**:
```
ext2: mounting /dev/vda1
ext2: superblock valid, magic=0xEF53, block_size=4096, 262144 blocks
ext2: 32 block groups, 8192 inodes per group
ls /mnt: . .. lost+found etc home
cat /mnt/etc/hostname: hadron
```

Test setup:
```bash
dd if=/dev/zero of=disk.img bs=1M count=64
mkfs.ext2 disk.img
mkdir -p mnt && mount disk.img mnt
mkdir -p mnt/etc
echo "hadron" > mnt/etc/hostname
umount mnt
# Pass to QEMU: -drive file=disk.img,format=raw,if=virtio
```

## Dependencies

- **Phase 8**: VFS integration (mount point, `Inode` and `FileSystem` traits)
- **Phase 10**: VirtIO-blk block device driver (`AsyncBlockDevice` implementation)
